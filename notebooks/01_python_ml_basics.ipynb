{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python + ML Basics for Architects\n",
    "\n",
    "A fast, friendly introduction to Python, data handling, and simple machine learning — using fake but architecture-flavored data.\n",
    "\n",
    "Goals:\n",
    "- Learn Python + pandas basics\n",
    "- Load and explore a dataset about windows/daylight/energy\n",
    "- Split into train/test, fit simple models, and evaluate\n",
    "- Understand cross-validation and overfitting with visuals\n",
    "- Get a small taste of neural nets via an `MLP` (\"deep learning vibe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "If you are on a fresh environment, you may need to install packages (run one by one if needed):\n",
    "\n",
    "```bash\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn scipy wordcloud\n",
    "```\n",
    "\n",
    "This notebook expects the repository structure with a `data/` and `scripts/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, warnings\n",
    "\n",
    "# Add repo root and scripts to import path when running from notebooks/\n",
    "if '__file__' in globals():\n",
    "    ROOT = Path(__file__).resolve().parents[1]\n",
    "else:\n",
    "    candidate = Path.cwd()\n",
    "    if (candidate / 'scripts').exists():\n",
    "        ROOT = candidate\n",
    "    elif candidate.name == 'notebooks' and (candidate.parent / 'scripts').exists():\n",
    "        ROOT = candidate.parent\n",
    "    else:\n",
    "        ROOT = candidate\n",
    "if str(ROOT / 'scripts') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'scripts'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from plotting_utils import set_style, plot_cv_folds, confusion_matrix_plot, learning_curve_plot, validation_curve_plot\n",
    "import data_simulation as sim\n",
    "\n",
    "set_style()\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python crashlet\n",
    "Python stores numbers, strings, lists, and dictionaries. You'll mostly use lists/dicts and then pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists and dicts\n",
    "sizes = [10, 20, 30]\n",
    "room = {\"name\": \"Studio A\", \"area_m2\": 120, \"seats\": 40}\n",
    "sizes.append(40)\n",
    "{\"sizes\": sizes, \"room\": room}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and pandas basics\n",
    "import numpy as np, pandas as pd\n",
    "a = np.array([1,2,3])\n",
    "df = pd.DataFrame({\"x\": [1,2,3], \"y\": [3,2,1]})\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (or generate) architecture-flavored dataset\n",
    "We use fake data that mimics window-to-wall ratio (wwr), shading depth, orientation, and energy/daylight outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ROOT / 'data' / 'building_performance_fake.csv'\n",
    "if not data_path.exists():\n",
    "    # Generate defaults if missing\n",
    "    sim.save_default_fake_data(ROOT)\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['wwr','shading_depth_m','daylit_area','glare_probability','cooling_kwh_m2']])\n",
    "plt.suptitle('Quick relationships', y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression: predict cooling energy from design inputs\n",
    "We fit a simple linear model and evaluate on a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['wwr','shading_depth_m','orientation','glazing_u_w_m2k']\n",
    "target = 'cooling_kwh_m2'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "cat = ['orientation']\n",
    "num = ['wwr','shading_depth_m','glazing_u_w_m2k']\n",
    "pre = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(drop='first'), cat),\n",
    "    (\"num\", 'passthrough', num)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "reg = Pipeline([('pre', pre), ('model', LinearRegression())])\n",
    "reg.fit(X_train, y_train)\n",
    "pred = reg.predict(X_test)\n",
    "r2 = r2_score(y_test, pred)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "r2, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, pred, alpha=0.8)\n",
    "plt.xlabel('Actual cooling kWh/m²')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title(f'Linear Regression: R²={r2:.2f}, MAE={mae:.1f}')\n",
    "m = np.array([y_test.min(), y_test.max()])\n",
    "plt.plot(m, m, 'k--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: comfortable daylight?\n",
    "Define a simple label: comfortable if `glare_probability < 0.35` and `daylit_area > 0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comfortable'] = ((df['glare_probability'] < 0.35) & (df['daylit_area'] > 0.5)).astype(int)\n",
    "Xc = df[['wwr','shading_depth_m','orientation']]\n",
    "yc = df['comfortable']\n",
    "pre_c = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(drop='first'), ['orientation']),\n",
    "    (\"num\", 'passthrough', ['wwr','shading_depth_m'])\n",
    "])\n",
    "Xtr, Xte, ytr, yte = train_test_split(Xc, yc, test_size=0.25, random_state=42, stratify=yc)\n",
    "clf = Pipeline([('pre', pre_c), ('model', LogisticRegression(max_iter=1000))])\n",
    "clf.fit(Xtr, ytr)\n",
    "predc = clf.predict(Xte)\n",
    "acc = accuracy_score(yte, predc)\n",
    "cm = confusion_matrix(yte, predc)\n",
    "acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_plot(cm, class_names=(\"Not Comfortable\",\"Comfortable\"), title=f'Logistic Regression (Accuracy={acc:.2f})');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and overfitting\n",
    "We vary model complexity (polynomial degree) and show CV scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_scores = []\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for deg in range(1,7):\n",
    "    poly = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    pipe = Pipeline([('pre', pre), ('poly', poly), ('ridge', Ridge(alpha=1.0))])\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring='r2')\n",
    "    deg_scores.append((deg, scores.mean(), scores.std()))\n",
    "\n",
    "ds = pd.DataFrame(deg_scores, columns=['degree','cv_mean','cv_std'])\n",
    "plt.errorbar(ds['degree'], ds['cv_mean'], yerr=ds['cv_std'], fmt='o-')\n",
    "plt.xlabel('Polynomial degree (complexity)')\n",
    "plt.ylabel('CV R²')\n",
    "plt.title('Overfitting demo: watch CV score peak then drop')\n",
    "plt.tight_layout(); plt.show()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing CV folds (\"crazily simple\")\n",
    "Each row is a fold; green cells are train, red cells are test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "_ = plot_cv_folds(n_samples=len(X), cv_splits=cv2.split(np.arange(len(X))), title='5-fold CV: train vs test membership')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tiny taste of \"deep learning\": MLP\n",
    "A small neural network classifier. This is just to build intuition — it’s not magic, and simple models are often enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Pipeline([('pre', pre_c), ('mlp', MLPClassifier(hidden_layer_sizes=(16,8), max_iter=1000, random_state=42))])\n",
    "mlp.fit(Xtr, ytr)\n",
    "acc_mlp = accuracy_score(yte, mlp.predict(Xte))\n",
    "acc, acc_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve (optional)\n",
    "How performance improves with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = learning_curve_plot(clf, Xc, yc, cv=5, scoring='accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key ideas\n",
    "- Always hold out test data or use cross-validation\n",
    "- Start simple; only add complexity if it improves validated performance\n",
    "- Document random seeds and settings for reproducibility\n",
    "- \"Deep\" models need more data and care; don’t overfit\n",
    "\n",
    "Next: a richer notebook focused on visualizing pilot results and making figures for stakeholders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
